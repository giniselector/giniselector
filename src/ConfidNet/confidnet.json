{
    "epochs": 300,
    "batch_size":  128,
    "optimizer": "adam",
    "lr_scheduler": "none",
    "optimizer_kwargs": {
        "lr": 0.0001
    }
}
